{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statemets\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from customScripts import utilities as util\n",
    "from customScripts import features as feat\n",
    "from customScripts import onset\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "#number of samples / second\n",
    "sampling_rate = 100000 #96000\n",
    "\n",
    "#length of frame in samples\n",
    "frame_length = 2000 #2048\n",
    "\n",
    "#number of samples used as offset for earch consecutive frame\n",
    "hop_length = 1000 #1024\n",
    "\n",
    "#number of mel frequency bins to use\n",
    "bin_number = 40 #80\n",
    "\n",
    "#set the desired number of frames / second here\n",
    "ground_thruth_conversion_const = 100 #2 # not used\n",
    "\n",
    "#input data\n",
    "#file_paths = ['music_data/shortName.flac']\n",
    "#grount_truth_paths = ['music_data/shortName.onsets']\n",
    "# prediction_paths = ['predictions/Muppets-02-01-01.csv', 'predictions/Muppets-02-04-04.csv', 'predictions/Muppets-03-04-03.csv']\n",
    "# file_lengths = [1547, 1548, 1539] #in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File loading and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train file paths\n",
    "train_onsets_gt_paths, train_beats_gt_paths, train_bpm_gt_paths, train_onsets_audio_paths, train_beats_audio_paths, train_bpm_audio_paths = util.get_file_paths('music_data/train')\n",
    "# get test file paths\n",
    "test_onsets_gt_paths, test_beats_gt_paths, test_bpm_gt_paths, test_onsets_audio_paths, test_beats_audio_paths, test_bpm_audio_paths = util.get_file_paths('music_data/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load single audio\n",
    "# ah_development_guitar_2684_TexasMusicForge_Dandelion_pt1\n",
    "single_audio = util.load_audio('music_data/train/al_Media-103515(9.1-19.1).flac', sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame number: 1001\n",
      "bin number: 40\n"
     ]
    }
   ],
   "source": [
    "# compute single audio spectrogram\n",
    "single_spectrogram = feat.compute_spectrogram(single_audio, frame_length, hop_length, bin_number)\n",
    "single_spectrogram_T = single_spectrogram.transpose()\n",
    "print('frame number:',len(single_spectrogram_T))\n",
    "print('bin number:',len(single_spectrogram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02, 0.3, 0.4, 0.67, 0.76, 1.02, 1.15, 1.16, 1.4, 1.44, 1.52, 1.8, 1.91, 1.92, 2.17, 2.26, 2.52, 2.55, 2.65, 2.71, 2.93, 3.02, 3.3, 3.39, 3.6, 3.76, 4.02, 4.13, 4.38, 4.42, 4.5, 4.76, 4.88, 5.25, 5.5, 5.54, 5.63, 5.89, 5.99, 6.27, 6.38, 6.75, 7.02, 7.13, 7.4, 7.49, 7.51, 7.88, 8.13, 8.24, 8.27, 8.49, 8.63, 8.9, 9.01, 9.26, 9.37, 9.63, 9.74, 9.87]\n",
      "[]\n",
      "160.0\n"
     ]
    }
   ],
   "source": [
    "# compute ground truth for single audio\n",
    "single_gt_path_onsets = 'music_data/train/al_Media-103515(9.1-19.1).onsets'\n",
    "single_gt_path_beats = 'music_data/train/al_Media-103515(9.1-19.1).beats'\n",
    "single_gt_path_bpm = 'music_data/train/al_Media-103515(9.1-19.1).bpm'\n",
    "\n",
    "sigle_gt_onsets = util.load_onsets_gt(single_gt_path_onsets, '/n')\n",
    "sigle_gt_beats = util.load_beats_gt(single_gt_path_beats, '/n')\n",
    "single_gt_bpm = util.load_bpm_gt(single_gt_path_bpm, '/n')\n",
    "\n",
    "print(sigle_gt_onsets)\n",
    "print(sigle_gt_beats)\n",
    "print(single_gt_bpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load onsets audio\n",
    "train_onsets_audio = util.load_audios(train_onsets_audio_paths, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute onsets audio spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ground truth for onsets audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load beats audio\n",
    "train_beats_audio = util.load_audios(train_beats_audio_paths, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute beats audio spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ground truth for beats audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bpm audio\n",
    "train_bpm_audio = util.load_audios(train_bpm_audio_paths, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute bpm audio spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ground truth for bpm audio\n",
    "train_bpm_gt = util.load_ground_truths(train_bpm_gt_paths, '/n')\n",
    "print(train_bpm_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ground truth, pad it with zeroes and adjust to frame number\n",
    "\n",
    "#episode 1\n",
    "\"\"\"\n",
    "gt_1 = util.load_ground_truth(grount_truth_paths[0], '/n')\n",
    "gt_1 = util.compute_0_padded_gt(gt_1, file_lengths[0])\n",
    "gt_1 = util.adjust_gt_to_frames(gt_1, ground_thruth_conversion_const)\n",
    "# append zeros so that lenght equals the frames list length\n",
    "for i in range(len(spectrogram_1T) - len(gt_1)):\n",
    "    gt_1.append(0)\n",
    "print('ground truth size:',len(gt_1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate training data\n",
    "\"\"\"\n",
    "gt_train = gt_1 + gt_2\n",
    "\n",
    "spectrogram_train = np.concatenate((spectrogram_1T, spectrogram_2T), axis=0)\n",
    "\n",
    "spectrogram_predict = spectrogram_3T\n",
    "\n",
    "#spectrogram_train[3195] == spectrogram_2T[100]\n",
    "\"\"\"\n",
    "#for i,g in enumerate(gt_train):\n",
    "#    if g == 1:\n",
    "#        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic onset detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01     1742.6392129428284\n",
      "0.02     1600.7588761630718\n",
      "0.3     1801.2446125331671\n",
      "0.75     1822.5924735585686\n",
      "0.76     1632.8056901210032\n",
      "1.15     1587.9560521283174\n",
      "1.49     7875.300035069225\n",
      "1.5     1882.0180840719413\n",
      "1.52     2043.8718512218793\n",
      "2.26     1666.8560254506956\n",
      "3.02     1507.6319824731281\n",
      "3.74     1752.6967106371621\n",
      "3.75     2720.5941962364595\n",
      "3.76     3136.860407678414\n",
      "4.37     1554.4353469450339\n",
      "4.47     1595.3874809142633\n",
      "4.49     3007.067819069324\n",
      "4.5     2256.413859780441\n",
      "4.75     1554.6523644829608\n",
      "4.86     4732.329759478317\n",
      "5.21     1566.2847433313234\n",
      "5.6     1507.600289405688\n",
      "5.97     2772.0946463335895\n",
      "5.98     1911.2935683658259\n",
      "5.99     3146.4133197320093\n",
      "6.72     1958.0668389468638\n",
      "7.46     2374.6976953303392\n",
      "8.6     1595.6899785886158\n",
      "9.71     2053.5047510169798\n",
      "9.74     1856.5917227166296\n",
      "10.0     7823.449531895277\n",
      "music_data/train/al_Media-103515(9.1-19.1).onsets\n"
     ]
    }
   ],
   "source": [
    "odf_single = onset.compute_odf(single_spectrogram)\n",
    "peaks_single = onset.apply_threshold(odf_single, 1500)\n",
    "#print(peaks_single)\n",
    "\n",
    "for i, p in enumerate(peaks_single):\n",
    "    if p > 0:\n",
    "        print(i/100, '   ', p)\n",
    "\n",
    "print(single_gt_path_onsets)\n",
    "        \n",
    "        \n",
    "# maxima = o.pick_local_peaks(peaks)\n",
    "\n",
    "# print(maxima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier training and prediction for onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a Multi-layer Perceptron classifier with default parameters\n",
    "#clf = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.fit(spectrogram_train, gt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction = clf.predict(spectrogram_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(prediction_paths[2], prediction, delimiter=\"/n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for onset detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print('precision (micro average):',precision_score(gt_3, prediction, average='micro'))\n",
    "print('precision (macro average):',precision_score(gt_3, prediction, average='macro'))\n",
    "print('precision (weighted average):',precision_score(gt_3, prediction, average='weighted'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print('recall (micro average):',recall_score(gt_3, prediction, average='micro'))\n",
    "print('recall (macro average):',recall_score(gt_3, prediction, average='macro'))\n",
    "print('recall (weighted average):',recall_score(gt_3, prediction, average='weighted'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print('f1 (micro average):',f1_score(gt_3, prediction, average='micro'))\n",
    "print('f1 (macro average):',f1_score(gt_3, prediction, average='macro'))\n",
    "print('f1 (weighted average):',f1_score(gt_3, prediction, average='weighted'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# calculate false positive / true positive rate and area under curve\n",
    "fpr, tpr, threshold = roc_curve(gt_3, prediction)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
