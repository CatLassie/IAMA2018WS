{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statemets\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from customScripts import utilities as util\n",
    "from customScripts import features as feat\n",
    "from customScripts import onset\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "#number of samples / second\n",
    "sampling_rate = 100000 #96000\n",
    "\n",
    "#length of frame in samples\n",
    "frame_length = 2000 #2048\n",
    "\n",
    "#number of samples used as offset for earch consecutive frame\n",
    "hop_length = 1000 #1024\n",
    "\n",
    "#number of mel frequency bins to use\n",
    "bin_number = 40 #80\n",
    "\n",
    "# size of the running window (in frames) for the threshold function\n",
    "threshold_window_size = 60\n",
    "\n",
    "#set the desired number of frames / second here\n",
    "ground_thruth_conversion_const = 100 #2 # not used\n",
    "\n",
    "# get train file paths\n",
    "train_onsets_gt_paths, train_beats_gt_paths, train_bpm_gt_paths, train_onsets_audio_paths, train_beats_audio_paths, train_bpm_audio_paths = util.get_file_paths('music_data/train')\n",
    "# get test file paths\n",
    "test_onsets_gt_paths, test_beats_gt_paths, test_bpm_gt_paths, test_onsets_audio_paths, test_beats_audio_paths, test_bpm_audio_paths = util.get_file_paths('music_data/test')\n",
    "\n",
    "# prediction_paths = ['predictions/Muppets-02-01-01.csv', 'predictions/Muppets-02-04-04.csv', 'predictions/Muppets-03-04-03.csv']\n",
    "# file_lengths = [1547, 1548, 1539] #in seconds\n",
    "\n",
    "# single file paths\n",
    "single_audio_path = 'music_data/train/al_Media-103515(9.1-19.1).flac' #ah_development_guitar_2684_TexasMusicForge_Dandelion_pt1\n",
    "single_gt_path_onsets = 'music_data/train/al_Media-103515(9.1-19.1).onsets'#ah_development_guitar_2684_TexasMusicForge_Dandelion_pt1\n",
    "single_gt_path_beats = 'music_data/train/al_Media-103515(9.1-19.1).beats'\n",
    "single_gt_path_bpm = 'music_data/train/al_Media-103515(9.1-19.1).bpm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File loading and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load single audio\n",
    "single_audio = util.load_audio(single_audio_path, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute single audio spectrogram\n",
    "single_spectrogram = feat.compute_spectrogram(single_audio, frame_length, hop_length, bin_number)\n",
    "single_spectrogram_T = single_spectrogram.transpose()\n",
    "\n",
    "#print('frame number:',len(single_spectrogram_T))\n",
    "#print('bin number:',len(single_spectrogram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ground truth for single audio\n",
    "single_gt_onsets = util.load_onsets_gt(single_gt_path_onsets, '/n')\n",
    "single_gt_beats = util.load_beats_gt(single_gt_path_beats, '/n')\n",
    "single_gt_bpm = util.load_bpm_gt(single_gt_path_bpm, '/n')\n",
    "\n",
    "#print(single_gt_onsets)\n",
    "#print(single_gt_beats)\n",
    "#print(single_gt_bpm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load onsets audio\n",
    "train_onsets_audio = util.load_audios(train_onsets_audio_paths, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute onsets audio spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ground truth for onsets audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load beats audio\n",
    "train_beats_audio = util.load_audios(train_beats_audio_paths, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute beats audio spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ground truth for beats audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load bpm audio\n",
    "train_bpm_audio = util.load_audios(train_bpm_audio_paths, sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute bpm audio spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ground truth for bpm audio\n",
    "train_bpm_gt = util.load_ground_truths(train_bpm_gt_paths, '/n')\n",
    "print(train_bpm_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ground truth, pad it with zeroes and adjust to frame number\n",
    "\n",
    "#episode 1\n",
    "\"\"\"\n",
    "gt_1 = util.load_ground_truth(grount_truth_paths[0], '/n')\n",
    "gt_1 = util.compute_0_padded_gt(gt_1, file_lengths[0])\n",
    "gt_1 = util.adjust_gt_to_frames(gt_1, ground_thruth_conversion_const)\n",
    "# append zeros so that lenght equals the frames list length\n",
    "for i in range(len(spectrogram_1T) - len(gt_1)):\n",
    "    gt_1.append(0)\n",
    "print('ground truth size:',len(gt_1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate training data\n",
    "\"\"\"\n",
    "gt_train = gt_1 + gt_2\n",
    "\n",
    "spectrogram_train = np.concatenate((spectrogram_1T, spectrogram_2T), axis=0)\n",
    "\n",
    "spectrogram_predict = spectrogram_3T\n",
    "\n",
    "#spectrogram_train[3195] == spectrogram_2T[100]\n",
    "\"\"\"\n",
    "#for i,g in enumerate(gt_train):\n",
    "#    if g == 1:\n",
    "#        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic onset detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "odf_single = onset.compute_odf(single_spectrogram)\n",
    "peaks_single = onset.apply_threshold(odf_single, 61, True)\n",
    "\n",
    "\"\"\"\n",
    "for i, p in enumerate(peaks_single):\n",
    "    if p > 0:\n",
    "        print(i/100, '   ', p)\n",
    "\"\"\"\n",
    "\n",
    "maxima_frame_indices = onset.pick_local_peaks(peaks_single)\n",
    "onset_time_stamps = maxima_frame_indices / 100\n",
    "\n",
    "print(len(onset_time_stamps))\n",
    "print(len(single_gt_onsets))\n",
    "for i in range(61):\n",
    "    if i < 60:\n",
    "        print('predicted: ', onset_time_stamps[i], '   actual: ', single_gt_onsets[i])\n",
    "    else:\n",
    "        print('predicted: ', onset_time_stamps[i],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier training and prediction for onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a Multi-layer Perceptron classifier with default parameters\n",
    "#clf = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.fit(spectrogram_train, gt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction = clf.predict(spectrogram_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(prediction_paths[2], prediction, delimiter=\"/n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for onset detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print('precision (micro average):',precision_score(gt_3, prediction, average='micro'))\n",
    "print('precision (macro average):',precision_score(gt_3, prediction, average='macro'))\n",
    "print('precision (weighted average):',precision_score(gt_3, prediction, average='weighted'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print('recall (micro average):',recall_score(gt_3, prediction, average='micro'))\n",
    "print('recall (macro average):',recall_score(gt_3, prediction, average='macro'))\n",
    "print('recall (weighted average):',recall_score(gt_3, prediction, average='weighted'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print('f1 (micro average):',f1_score(gt_3, prediction, average='micro'))\n",
    "print('f1 (macro average):',f1_score(gt_3, prediction, average='macro'))\n",
    "print('f1 (weighted average):',f1_score(gt_3, prediction, average='weighted'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# calculate false positive / true positive rate and area under curve\n",
    "fpr, tpr, threshold = roc_curve(gt_3, prediction)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
