{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import statemets\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import auc\n",
    "import matplotlib.pyplot as plt\n",
    "from customScripts import utilities as util\n",
    "from customScripts import features as feat\n",
    "from customScripts import onset\n",
    "\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "#number of samples / second\n",
    "sampling_rate = 96000\n",
    "\n",
    "#length of frame in samples\n",
    "frame_length = 2048 #48000\n",
    "\n",
    "#number of samples used as offset for earch consecutive frame\n",
    "hop_length = 1024 #24000\n",
    "\n",
    "#number of mel frequency bins to use\n",
    "bin_number = 40 #80\n",
    "\n",
    "#set the desired number of frames / second here\n",
    "ground_thruth_conversion_const = 100 #2\n",
    "\n",
    "#input data\n",
    "file_paths = ['music_data/shortName.flac']\n",
    "grount_truth_paths = ['music_data/shortName.onsets']\n",
    "# prediction_paths = ['predictions/Muppets-02-01-01.csv', 'predictions/Muppets-02-04-04.csv', 'predictions/Muppets-03-04-03.csv']\n",
    "# file_lengths = [1547, 1548, 1539] #in seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File loading and feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n",
      "177\n",
      "107\n",
      "71\n",
      "0\n",
      "0\n",
      "D:\\uni\\2018WS\\IAMA\\exercise\\repo\\ex1\\notebooks\\music_data\\train\\SoundCheck2_60_Vocal_Tenor_opera.flac\n"
     ]
    }
   ],
   "source": [
    "train_onsets_gt_names, train_beats_gt_names, train_bpm_gt_names, train_onsets_audio_names, train_beats_audio_names, train_bpm_audio_names = util.get_file_names('music_data/train')\n",
    "#print(len(train_onsets_audio_names))\n",
    "#print(len(train_beats_audio_names))\n",
    "#print(len(train_bpm_audio_names))\n",
    "\n",
    "test_onsets_gt_names, test_beats_gt_names, test_bpm_gt_names, test_onsets_audio_names, test_beats_audio_names, test_bpm_audio_names = util.get_file_names('music_data/test')\n",
    "#print(len(test_onsets_audio_names))\n",
    "#print(len(test_beats_audio_names))\n",
    "#print(len(test_bpm_audio_names))\n",
    "\n",
    "#print(train_onsets_audio_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load audio\n",
    "y_1 = util.load_audio(train_onsets_audio_names[0], sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame number: 5232\n",
      "bin number: 40\n"
     ]
    }
   ],
   "source": [
    "#compute spectrograms\n",
    "spectrogram_1 = feat.compute_spectrogram(y_1, frame_length, hop_length, bin_number)\n",
    "spectrogram_1T = spectrogram_1.transpose()\n",
    "print('frame number:',len(spectrogram_1T))\n",
    "print('bin number:',len(spectrogram_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ground truth, pad it with zeroes and adjust to frame number\n",
    "\n",
    "#episode 1\n",
    "\"\"\"\n",
    "gt_1 = util.load_ground_truth(grount_truth_paths[0], '/n')\n",
    "gt_1 = util.compute_0_padded_gt(gt_1, file_lengths[0])\n",
    "gt_1 = util.adjust_gt_to_frames(gt_1, ground_thruth_conversion_const)\n",
    "# append zeros so that lenght equals the frames list length\n",
    "for i in range(len(spectrogram_1T) - len(gt_1)):\n",
    "    gt_1.append(0)\n",
    "print('ground truth size:',len(gt_1))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate training data\n",
    "\"\"\"\n",
    "gt_train = gt_1 + gt_2\n",
    "\n",
    "spectrogram_train = np.concatenate((spectrogram_1T, spectrogram_2T), axis=0)\n",
    "\n",
    "spectrogram_predict = spectrogram_3T\n",
    "\n",
    "#spectrogram_train[3195] == spectrogram_2T[100]\n",
    "\"\"\"\n",
    "#for i,g in enumerate(gt_train):\n",
    "#    if g == 1:\n",
    "#        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic onset detection method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.16     4911.687614667323\n",
      "0.17     3552.829881252663\n",
      "0.63     1941.8000888872089\n",
      "0.64     1692.6766333500432\n",
      "0.65     1626.093914146778\n",
      "0.85     2036.849908839988\n",
      "1.37     1910.2390218664327\n",
      "1.39     2018.7514144460258\n",
      "1.68     4487.366100037915\n",
      "1.7     1659.7639448022796\n",
      "1.91     2142.0263151935633\n",
      "3.4     2187.8340567633704\n",
      "3.42     5084.729949639742\n",
      "3.99     3707.5819156282364\n",
      "4.0     2445.5957110759296\n",
      "4.99     1544.060931938878\n",
      "5.53     1587.0497328776692\n",
      "7.01     3092.9744244063895\n",
      "7.02     1555.8084514737336\n",
      "7.3     2242.052599448835\n",
      "7.52     2463.9116376886536\n",
      "9.6     1675.896638076603\n",
      "9.63     1847.9743087957797\n",
      "9.66     1917.207417691683\n",
      "10.15     1911.0561536804762\n",
      "13.13     4899.612580836143\n",
      "27.73     2216.2161098005868\n",
      "28.3     1605.0368495252037\n",
      "28.59     2935.736820641721\n",
      "36.07     1754.7857735188145\n",
      "36.08     1658.552512720222\n",
      "36.59     2823.4605172942224\n",
      "40.59     15242.250134518508\n",
      "40.62     1872.800057328098\n",
      "40.99     3656.443912174542\n",
      "41.0     3207.202538269558\n",
      "41.01     2013.0388234711131\n",
      "D:\\uni\\2018WS\\IAMA\\exercise\\repo\\ex1\\notebooks\\music_data\\train\\SoundCheck2_60_Vocal_Tenor_opera.onsets\n"
     ]
    }
   ],
   "source": [
    "odf_1 = onset.compute_odf(spectrogram_1)\n",
    "peaks_1 = onset.apply_threshold(odf_1, 1500)\n",
    "#print(peaks_1)\n",
    "\n",
    "for i, p in enumerate(peaks_1):\n",
    "    if p > 0:\n",
    "        print(i/100, '   ', p)\n",
    "\n",
    "print(train_onsets_gt_names[0])\n",
    "        \n",
    "        \n",
    "# maxima = o.pick_local_peaks(peaks)\n",
    "\n",
    "# print(maxima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier training and prediction for onsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use a Multi-layer Perceptron classifier with default parameters\n",
    "#clf = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clf.fit(spectrogram_train, gt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction = clf.predict(spectrogram_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savetxt(prediction_paths[2], prediction, delimiter=\"/n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation for onset detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print('precision (micro average):',precision_score(gt_3, prediction, average='micro'))\n",
    "print('precision (macro average):',precision_score(gt_3, prediction, average='macro'))\n",
    "print('precision (weighted average):',precision_score(gt_3, prediction, average='weighted'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print('recall (micro average):',recall_score(gt_3, prediction, average='micro'))\n",
    "print('recall (macro average):',recall_score(gt_3, prediction, average='macro'))\n",
    "print('recall (weighted average):',recall_score(gt_3, prediction, average='weighted'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "print('f1 (micro average):',f1_score(gt_3, prediction, average='micro'))\n",
    "print('f1 (macro average):',f1_score(gt_3, prediction, average='macro'))\n",
    "print('f1 (weighted average):',f1_score(gt_3, prediction, average='weighted'))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# calculate false positive / true positive rate and area under curve\n",
    "fpr, tpr, threshold = roc_curve(gt_3, prediction)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# plot ROC curve\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
